<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>圖書館 or 健身房?</title>
  <meta name="description" content="Memories in the military.">


  <link rel="stylesheet" href="/the-military-grind/css/tufte.css">	
  

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  
  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');

  </script>

  <link rel="canonical" href="/the-military-grind/chap_2/library_or_gym/">
  <link rel="alternate" type="application/rss+xml" title="The Military Grind" href="/the-military-grind/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
        <a href="/the-military-grind/">Contents</a>
	   <a href="http://yclin.me/">About Me</a>
	</nav>
</header>

    <article class="group">
      <h1>圖書館 or 健身房?</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        Exp: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<p>來到兵器連認識了 Zack, Vibert 等人以後, 寢室就變成了他們的健身房. 而我與晨勃, 屈暄等人
則把寢室當成貨真價實的圖書館.</p>

<h2 id="markov-random-fields">Markov Random Fields</h2>

<p><label for="nb1" class="margin-toggle">⊕</label><input type="checkbox" id="nb1" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/the-military-grind/assets/img/mrf.png" /><br />Undirected graphical representation of a joint probability of voting preferences over four individuals. The figure on the right illustrates the pairwise factors present in the model.</span> As a motivating example, suppose that we are modeling voting preferences among persons <script type="math/tex">A,B,C,D</script>. Let’s say that <script type="math/tex">(A,B)</script>, <script type="math/tex">(B,C)</script>, <script type="math/tex">(C,D)</script>, and <script type="math/tex">(D,A)</script> are friends, and friends tend to have similar voting preferences. These influences can be naturally represented by an undirected graph.</p>

<p>One way to define a probability over the joint voting decision of <script type="math/tex">A,B,C,D</script> is to assign scores to each assignment to these variables and then define a probability as a normalized score. A score can be any function, but in our case, we will define it to be of the form</p>
<div class="mathblock"><script type="math/tex; mode=display">
\tilde p(A,B,C,D) = \phi(A,B)\phi(B,C)\phi(C,D)\phi(D,A),
</script></div>
<p>where <script type="math/tex">\phi(X,Y)</script> is a factor that assigns more weight to consistent votes among friends <script type="math/tex">X,Y</script>, e.g.:</p>
<div class="mathblock"><script type="math/tex; mode=display">
\begin{align*}
\phi(X,Y) =
\begin{cases}
10 & \text{ if}\; X = Y = 1 \\
5 & \text{ if}\; X = Y = 0 \\
1 & \text{ otherwise}.
\end{cases}
\end{align*}
</script></div>
<p>The factors in the unnormalized distribution are often referred to as <em>factors</em>.
The final probability is then defined as</p>
<div class="mathblock"><script type="math/tex; mode=display">
p(A,B,C,D) = \frac{1}{Z} \tilde p(A,B,C,D),
</script></div>
<p>where <script type="math/tex">Z = \sum_{A,B,C,D} \tilde p(A,B,C,D)</script> is a normalizing constant that ensures that the distribution sums to one.</p>

<p>When normalized, we can view <script type="math/tex">\phi(A,B)</script> as an interaction that pushes <script type="math/tex">B</script>’s vote closer to that of <script type="math/tex">A</script>. The term <script type="math/tex">\phi(B,C)</script> pushes <script type="math/tex">B</script>’s vote closer to <script type="math/tex">C</script>, and the most likely vote will require reconciling these conflicting influences.</p>

<p>Note that unlike in the directed case, we are not saying anything about how one variable is generated from another set of variables (as a conditional probability distribution would do). We simply indicate a level of coupling between dependent variables in the graph. In a sense, this requires less prior knowledge, as we no longer have to specify a full generative story of how the vote of <script type="math/tex">B</script> is constructed from the vote of <script type="math/tex">A</script> (which we would need to do if we had a <script type="math/tex">P(B\mid A)</script> factor). Instead, we simply identify dependent variables and define the strength of their interactions; this in turn defines an energy landscape over the space of possible assignments and we convert this energy to a probability via the normalization constant.</p>

<h3 id="formal-definition">Formal definition</h3>

<p>A Markov Random Field (MRF) is a probability distribution <script type="math/tex">p</script> over variables <script type="math/tex">x_1,...,x_n</script> defined by an <em>undirected</em> graph <script type="math/tex">G</script> in which nodes correspond to variables <script type="math/tex">x_i</script>. The probability <script type="math/tex">p</script>
has the form</p>
<div class="mathblock"><script type="math/tex; mode=display">
p(x_1,..,x_n) = \frac{1}{Z} \prod_{c \in C} \phi_c(x_c),
</script></div>
<p>where <script type="math/tex">C</script> denotes the set of <em>cliques</em> (i.e. fully connected subgraphs) of <script type="math/tex">G</script>.
The value</p>
<div class="mathblock"><script type="math/tex; mode=display">
Z = \sum_{x_1,..,x_n}\prod_{c \in C} \phi_c(x_c)
</script></div>
<p>is a normalizing constant that ensures that the distribution sums to one.</p>

<p>Thus, given a graph <script type="math/tex">G</script>, our probability distribution may contain factors whose scope is any clique in <script type="math/tex">G</script>, which can be a single node, an edge, a triangle, etc. Note that we do not need to specify a factor for each clique. In our above example, we defined a factor over each edge (which is a clique of two nodes). However, we chose not to specify any unary factors i.e. cliques over single nodes.</p>

<h3 id="comparison-to-bayesian-networks">Comparison to Bayesian networks</h3>

<p><label for="nb1" class="margin-toggle">⊕</label><input type="checkbox" id="nb1" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/the-military-grind/assets/img/mrf2.png" /><br />Examples of directed models for our four-variable voting example. None of them can accurately express our prior knowledge about the dependency structure among the variables.</span>
In our earlier voting example, we had a distribution over <script type="math/tex">A,B,C,D</script> that satisfied <script type="math/tex">A \perp C \mid  \{B,D\}</script> and <script type="math/tex">B \perp D \mid  \{A,C\}</script> (because only friends directly influence a person’s vote). We can easily check by counter-example that these independencies cannot be perfectly represented by a Bayesian network.
However, the MRF turns out to be a perfect map for this distribution.</p>

<p>More generally, MRFs have several advantages over directed models:</p>

<ul>
  <li>They can be applied to a wider range of problems in which there is no natural directionality associated with variable dependencies.</li>
  <li>Undirected graphs can succinctly express certain dependencies that Bayesian nets cannot easily describe (although the converse is also true)</li>
</ul>

<p>They also possess several important drawbacks:</p>

<ul>
  <li>Computing the normalization constant <script type="math/tex">Z</script> requires summing over a potentially exponential number of assignments. We will see that in the general case, this will be NP-hard; thus many undirected models will be intractable and will require approximation techniques.</li>
  <li>Undirected models may be difficult to interpret.</li>
  <li>It is much easier to generate data from a Bayesian network, which is important in some applications.</li>
</ul>

<p>It is not hard to see that Bayesian networks are a special case of MRFs with a very specific type of clique factor (one that corresponds to a conditional probability distribution and implies a directed acyclic structure in the graph), and a normalizing constant of one. In particular, if we take a directed graph <script type="math/tex">G</script> and add side edges to all parents of a given node (and removing their directionality), then the CPDs (seen as factors over a variable and its ancestors) factorize over the resulting undirected graph. The resulting process is called <em>moralization</em>.</p>
<figure><figcaption>A Bayesian network can always be converted into an undirected network with normalization constant one. The converse is also possible, but may be computationally intractable, and may produce a very large (e.g. fully connected) directed graph.</figcaption><img src="/the-military-grind/assets/img/moralization.png" /></figure>

<p>Thus, MRFs have more power than Bayesian networks, but are more difficult to deal with computationally. A general rule of thumb is to use Bayesian networks whenever possible, and only switch to MRFs if there is no natural way to model the problem with a directed graph (like in our voting example).</p>

<h2 id="independencies-in-markov-random-fields">Independencies in Markov Random Fields</h2>

<p>Recall that in the case of Bayesian networks, we defined a set of independencies <script type="math/tex">I(G)</script> that were described by a directed graph <script type="math/tex">G</script>, and showed how these describe true independencies that must hold in a distribution <script type="math/tex">p</script> that factorizes over the directed graph, i.e. <script type="math/tex">I(G) \subseteq I(p)</script>.</p>

<p><label for="markovblanket" class="margin-toggle">⊕</label><input type="checkbox" id="markovblanket" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/the-military-grind/assets/img/markovblanket.png" /><br />In an MRF, a node <script type="math/tex">X</script> is independent from the rest of the graph given its neighbors (which are reffered to at the Markov blanket of <script type="math/tex">X</script>.</span>
What independencies can be then described by an undirected MRF? The answer here is very simple and intuitive: variables <script type="math/tex">x,y</script> are dependent if they are connected by a path of unobserved variables. However, if <script type="math/tex">x</script>’s neighbors are all observed, then <script type="math/tex">x</script> is independent of all the other variables, since they influence <script type="math/tex">x</script> only via its neighbors.</p>

<p>In particular, if a set of observed variables forms a cut-set between two halves of the graph, then variables in one half are independent from ones in the other.</p>

<figure><figcaption></figcaption><img src="/the-military-grind/assets/img/cutset.png" /></figure>

<p>Formally, we define the <em>Markov blanket</em> <script type="math/tex">U</script> of a variable <script type="math/tex">X</script> as the minimal set of nodes such that <script type="math/tex">X</script> is independent from the rest of the graph if <script type="math/tex">U</script> is observed, i.e. <script type="math/tex">X \perp (\mathcal{X} - \{X\} - U) \mid  U</script>. This notion holds for both directed and undirected models, but in the undirected case the Markov blanket turns out to simply equal a node’s neighborhood.</p>

<p>In the directed case, we found that <script type="math/tex">I(G) \subseteq I(p)</script>, but there were distributions <script type="math/tex">p</script> whose independencies could not be described by <script type="math/tex">G</script>. In the undirected case, the same holds. For example, consider a probability described by a directed v-structure (i.e. the explaining away phenomenon). The undirected model cannot describe the independence assumption <script type="math/tex">X \perp Y</script>.</p>

<figure><figcaption>Examples of probability distributions that have a perfect directed graphical representation but no undirected representation, and vice-versa.</figcaption><img src="/the-military-grind/assets/img/mrf-bn-comparison.png" /></figure>

<h2 id="conditional-random-fields">Conditional Random Fields</h2>

<p>An important special case of Markov Random Fields arises when they are applied to model a conditional probability distribution <script type="math/tex">p(y\mid x)</script>. In this case, <script type="math/tex">x \in \mathcal{X}</script> and <script type="math/tex">y \in \mathcal{Y}</script> are vector-valued variables; we are typically given <script type="math/tex">x</script> and want to say something interesting for <script type="math/tex">y</script>. Typically, distributions of this sort will arise in a supervised learning setting, where <script type="math/tex">y</script> will be a vector-valued label that we will be trying to predict. This setting is typically referred to as <em>structured prediction</em>.</p>

<h3 id="example">Example</h3>

<h2 id="section">不運動, 我會死</h2>

<p>It is often useful to view MRFs in a way where factors and variables are explicit and separate in the representation. A factor graph is one such way to do this. A factor graph is a bipartite graph where one group is the variables in the distribution being modeled, and the other group is the factors defined on these variables. Edges go between factors and variables that those factors depend on.</p>

<figure><figcaption>Example of a factor graph with three variables and four factors.</figcaption><img src="/the-military-grind/assets/img/factor-graph.png" /></figure>

<p>This view allows us to more readily see the factor dependencies between variables, and later we’ll see it allows us to compute some probability distributions more easily.</p>

<p><br /></p>

<table>
  <tbody>
    <tr>
      <td><a href="../../">Index</a></td>
      <td><a href="../directed">Previous</a></td>
      <td><a href="../../inference/ve">Next</a></td>
    </tr>
  </tbody>
</table>



    </article>
    <span class="print-footer">圖書館 or 健身房? - Yen-Chen Lin</span>
    <footer>
  <hr class="slender">
  <!-- <ul class="footer&#45;links"> -->
  <!--   <li><a href="mailto:hate@spam.net"><span class="icon&#45;mail"></span></a></li>     -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.twitter.com/twitter_handle"><span class="icon-twitter"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//plus.google.com/+googlePlusName"><span class="icon-googleplus"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//github.com/GithubHandle"><span class="icon-github"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.flickr.com/photos/FlickrUserID"><span class="icon-flickr"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="/feed"><span class="icon-feed"></span></a> -->
  <!--     </li> -->
  <!--      -->
  <!-- </ul> -->
<div class="credits">
<!-- <span>&#38;copy; 2018 <!&#45;&#45; &#38;#38;nbsp;&#38;#38;nbsp;YEN-CHEN LIN &#45;&#45;></span></br> <br> -->
<span>Site created with <a href="//jekyllrb.com">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme</a>. &copy; 2018</span> 
</div>  
</footer>

  </body>
</html>
